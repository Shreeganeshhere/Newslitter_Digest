TLDR Data
Costly S3 mistakes with Delta Lake include enabling object versioning, misusing archival storage classes, and routing traffic through NAT GatewaysÂ â€ŒÂ â€ŒÂ â€ŒÂ â€ŒÂ â€ŒÂ â€ŒÂ â€ŒÂ â€ŒÂ â€ŒÂ â€ŒÂ â€ŒÂ â€ŒÂ â€ŒÂ â€ŒÂ â€ŒÂ â€ŒÂ â€ŒÂ â€ŒÂ â€ŒÂ â€ŒÂ â€ŒÂ â€ŒÂ â€ŒÂ â€ŒÂ â€ŒÂ â€ŒÂ Â â€ŒÂ â€ŒÂ â€ŒÂ â€ŒÂ â€ŒÂ â€ŒÂ â€ŒÂ â€ŒÂ â€ŒÂ â€ŒÂ â€ŒÂ â€ŒÂ â€ŒÂ â€ŒÂ â€ŒÂ â€ŒÂ â€ŒÂ â€ŒÂ â€ŒÂ â€ŒÂ â€ŒÂ â€ŒÂ â€ŒÂ â€ŒÂ â€ŒÂ â€Œ
Sign Up
|
Advertise
|
View Online
T
L
D
R
TLDR Data
2025-12-08
ðŸ“±
Deep Dives
Expensive Delta Lake S3 Storage Mistakes (And How to Fix Them) (12 minute read)
Costly S3 mistakes with Delta Lake include enabling object versioning, misusing archival storage classes, routing traffic through NAT Gateways, and transitioning active files to infrequent-access tiers. Proper configuration prevents these issues and significantly reduces storage and data transfer costs.
Benchmarking Diskless Topics: Part 1 (11 minute read)
Benchmarks of Apache Kafka's KIP-1150 Diskless Topics on Aiven demonstrated sustained 1 GiB/s ingest and 3 GiB/s egress across three AZs using only six m8g.4xlarge nodes at <30% CPU, achieving ~1.6 s P99 end-to-end latency and over 94% infrastructure cost reduction (from â‰ˆ$3.32 M to under $288k per year) for typical multi-AZ workloads. Tradeoffs include minor increases in cross-AZ metadata traffic and higher JVM heap, but with negligible impact compared to savings in disk and replication costs. Open-source benchmarks and configs are available for reproducibility.
ðŸš€
Opinions & Advice
Duplication Isn't Always an Anti-Pattern (4 minute read)
Duplication is not always an anti-pattern: over-abstraction and shared dependencies often create tighter coupling, higher cognitive load, and harder changes. For data engineers, it is usually better to duplicate data models, Kafka topics, or business logic when ownership or context differs, while centralizing only truly universal utilities and repositories. Controlled duplication improves isolation, reduces blast radius, and makes systems easier to evolve over time.
Why We Built â€œBlaBlaCar Data Copilotâ€: Shifting Data Analysis Left (6 minute read)
Data Copilot is an AI-driven IDE extension that empowers software engineers to perform data analysis directly in their coding environment. It eliminates reliance on BI consoles and reduces organizational silos. Featuring business-specific curated queries, transparent SQL/Python code generation, and heuristic Data Health Cards, Data Copilot enforces analytics best practices and unit testing earlier in the cycle. This accelerates domain team autonomy by operationalizing Data Mesh principles while allowing for centralization of results. The tool is open source, and the code base is linked in the article.
When To Log, and When To Shut Up (4 minute read)
Logging indiscriminately generates vast volumes of costly, low-value data, hindering effective root cause analysis and inflating operational spend. Prioritize structured, contextual logs, and reserve logs for information that's truly actionable or irreducible to metrics and traces. Prestructured logging enables efficient aggregation and rapid analytics, reducing query latency from minutes to milliseconds. Intentional, well-scoped logging maximizes observability and minimizes noise and vendor costs.
ðŸ’»
Launches & Tools
OSMnx (GitHub Repo)
OSMnx is a Python library for quickly downloading, modeling, and analyzing street networks and urban geospatial data from OpenStreetMap. It provides a robust, open-source way for data engineers to integrate network-based geospatial data into analysis and pipelines with minimal setup.
Apache Flink 2.2.0: Advancing Real-Time Data + AI and Empowering Stream Processing for the AI Era (14 minute read)
Apache Flink 2.2.0 introduces seamless real-time AI integration, with built-in ML_PREDICT for LLM inference and VECTOR_SEARCH for streaming vector similarity, directly enabling advanced streaming AI workflows. Major enhancements include materialized tables, improved Delta Joins, balanced task scheduling, smarter connectors, optimized PyFlink async support, and upgrades to protobuf-java 4.32.1.
What is State Aware Orchestration and when should you (not) care? (11 minute read)
State-aware orchestration stores metadata about processed data so pipelines only run when new data arrives, reducing costs and complexity. While dbt Cloud markets this as novel, similar concepts exist in Spark, Iceberg, and other frameworks. It's most valuable for teams with 1,000+ models, many schedules, and unreliable data delivery. However, with good end-to-end orchestration, incremental models, and reliable data sources, traditional scheduling may suffice.
ðŸŽ
Miscellaneous
Autonomous Observability at Pinterest (10 minute read)
Pinterest replaced fragmented observability with a unified Model Context Protocol (MCP) server, giving AI agents like Tricorder single-point access to metrics (3B/min), logs/traces (7TB/day), alerts, changefeeds, and dependency graphs. This enabled autonomous correlation, faster root-cause analysis, and lower MTTR. It sets the stage for future LLM-driven issue resolution.
A Modern Guide to SQL JOINs (18 minute read)
LEFT JOIN with ID-only ON clauses forms the core foundation for SQL JOINs, preserving left-table rows and cleanly handling N:1 and 1:N relationships (with NULLs where needed). INNER JOIN is a filtered Cartesian product. Best practices include explicit aliases, N:1 join order for performance, nested-loop thinking, moving non-ID filters to WHERE, and avoiding Venn diagrams and non-equality ON conditions.
âš¡
Quick Links
Beyond the Context Window: A New Approach to Summarizing Big Data (7 minute read)
Flipkart's XL-OPSUMM summarizes large review datasets by chunking inputs and tracking aspect-level sentiment, enabling summarization beyond LLM context limits.
AWS Introduces Durable Functions: Stateful Logic Directly in Lambda Code (3 minute read)
AWS Durable Functions for Lambda enable stateful, long-running workflows directly in Lambda code, removing the need for Step Functions.
Want to advertise in TLDR? ðŸ“°
If your company is interested in reaching an audience of data engineering professionals and decision makers, you may want to
advertise with us
.
Want to work at TLDR? ðŸ’¼
Apply here
or send a friend's resume to
jobs@tldr.tech
and get $1k if we hire them!
If you have any comments or feedback, just respond to this email!
Thanks for reading,
Joel Van Veluwen
,
Tzu-Ruey Ching
&
Remi Turpaud
Manage your subscriptions
to our other newsletters on tech, startups, and programming. Or if TLDR Data isn't for you, please
unsubscribe
.